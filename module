import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor

data = pd.read_csv(r"C:\Users\samik\Downloads\visa_dataset.csv")
df = pd.DataFrame(data)
df["application_date"] = pd.to_datetime(df["application_date"])
df["decision_date"] = pd.to_datetime(df["decision_date"])
df["processing_days"] = (df["decision_date"] - df["application_date"]).dt.days
df_encoded = pd.get_dummies(df, columns=["country","visa_type"])

print(df["processing_days"].describe())
sns.histplot(df["processing_days"], kde=True)
plt.title("Distribution of Visa Processing Days")
plt.xlabel("Processing Days")
plt.ylabel("count")
plt.show()
sns.boxplot(x=df["processing_days"])
plt.title("Boxplot of Processing Days")
plt.show()
df["application_month"] = df["application_date"].dt.month
corr_matrix = df[["processing_days", "application_month"]].corr()
print(corr_matrix)
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()
sns.scatterplot(
    x="application_month",
    y="processing_days",
    data=df
)
plt.title("Processing Days vs Application Month")
plt.show()

print(df[["application_date", "application_month"]])
df['season']=df["application_month"].apply(
    lambda x: "Peak" if x in [1,2,3,12] else "off-peak"
)
print(df[["application_month", "season"]])

country_avg = df.groupby("country")["processing_days"].mean()
print(country_avg)

df["country_avg"] = df["country"].map(country_avg)

visa_avg = df.groupby("visa_type")["processing_days"].mean()
df["visa_avg"] = df["visa_type"].map(visa_avg)
print(df)

x = df_encoded.drop(
    columns=['processing_days','application_date','decision_date']
)
y = df_encoded["processing_days"]

x_train,x_test,y_train,y_test = train_test_split(
    x,y,test_size=0.3,random_state=42
)

model = LinearRegression()
model.fit(x_train,y_train)
y_pred = model.predict(x_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("MAE : ", mae)
print("RMSE : ", rmse)

#testing with random forest

rf_model = RandomForestRegressor(
    n_estimators=200,
    random_state=42
)

rf_model.fit(x_train, y_train)

rf_y_pred = rf_model.predict(x_test)

rf_mae = mean_absolute_error(y_test, rf_y_pred)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_y_pred))

print("Random Forest MAE :", rf_mae)
print("Random Forest RMSE :", rf_rmse)

#Gradient Boosting

gb_model = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.1,
    random_state=42
)

gb_model.fit(x_train, y_train)
gb_y_pred = gb_model.predict(x_test)

gb_mae = mean_absolute_error(y_test, gb_y_pred)
gb_rmse = np.sqrt(mean_squared_error(y_test, gb_y_pred))

print("Gradient Boosting MAE : ", gb_mae)
print("Gradient Boosting RMSE : ", gb_rmse)
