import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import GridSearchCV


data = pd.read_csv(r"C:\Users\samik\Downloads\visa_dataset.csv")
df = pd.DataFrame(data)
df["application_date"] = pd.to_datetime(df["application_date"])
df["decision_date"] = pd.to_datetime(df["decision_date"])
df["processing_days"] = (df["decision_date"] - df["application_date"]).dt.days
df_encoded = pd.get_dummies(df, columns=["country","visa_type"])

print(df["processing_days"].describe())
sns.histplot(df["processing_days"], kde=True)
plt.title("Distribution of Visa Processing Days")
plt.xlabel("Processing Days")
plt.ylabel("count")
plt.show()
sns.boxplot(x=df["processing_days"])
plt.title("Boxplot of Processing Days")
plt.show()
df["application_month"] = df["application_date"].dt.month
corr_matrix = df[["processing_days", "application_month"]].corr()
print(corr_matrix)
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()
sns.scatterplot(
    x="application_month",
    y="processing_days",
    data=df
)
plt.title("Processing Days vs Application Month")
plt.show()

print(df[["application_date", "application_month"]])
df['season']=df["application_month"].apply(
    lambda x: "Peak" if x in [1,2,3,12] else "off-peak"
)
print(df[["application_month", "season"]])

country_avg = df.groupby("country")["processing_days"].mean()
print(country_avg)

df["country_avg"] = df["country"].map(country_avg)

visa_avg = df.groupby("visa_type")["processing_days"].mean()
df["visa_avg"] = df["visa_type"].map(visa_avg)
print(df)

x = df_encoded.drop(
    columns=['processing_days','application_date','decision_date']
)
y = df_encoded["processing_days"]

x_train,x_test,y_train,y_test = train_test_split(
    x,y,test_size=0.3,random_state=42
)

#Linear Regression model

model = LinearRegression()
model.fit(x_train,y_train)
y_pred = model.predict(x_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("Linear Regression MAE : ", mae)
print(" Linear Regression RMSE : ", rmse)

print("Linear Regression R2 :", r2_score(y_test, y_pred))

#testing with random forest

rf = RandomForestRegressor(random_state=42)

rf_param_grid = {
    "n_estimators": [100, 200, 300],
    "max_depth": [None, 10, 20],
    "min_samples_split": [2, 5],
    "min_samples_leaf": [1, 2]
}

rf_grid = GridSearchCV(
    estimator=rf,
    param_grid=rf_param_grid,
    cv=5,
    scoring="neg_mean_absolute_error",
    n_jobs=-1
)

rf_grid.fit(x_train, y_train)

best_rf = rf_grid.best_estimator_

rf_y_pred = best_rf.predict(x_test)

rf_mae = mean_absolute_error(y_test, rf_y_pred)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_y_pred))
rf_r2 = r2_score(y_test, rf_y_pred)

print("Best Random Forest Parameters:", rf_grid.best_params_)
print("Tuned Random Forest MAE:", rf_mae)
print("Tuned Random Forest RMSE:", rf_rmse)
print("Tuned Random Forest R2:", rf_r2)


#Gradient Boosting

gb_model = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.1,
    random_state=42
)

gb_model.fit(x_train, y_train)
gb_y_pred = gb_model.predict(x_test)

gb_mae = mean_absolute_error(y_test, gb_y_pred)
gb_rmse = np.sqrt(mean_squared_error(y_test, gb_y_pred))

print("Gradient Boosting MAE : ", gb_mae)
print("Gradient Boosting RMSE : ", gb_rmse)

print("Gradient Boosting R2 :", r2_score(y_test, gb_y_pred))

#Model comparison using MAE, RMSE, RÂ² score

results = pd.DataFrame({
    "Model": [
        "Linear Regression (Baseline)",
        "Random Forest (Tuned)",
        "Gradient Boosting (Baseline)"
    ],
    "MAE": [
        mae,
        rf_mae,
        gb_mae
    ],
    "RMSE": [
        rmse,
        rf_rmse,
        gb_rmse
    ],
    "R2 Score": [
        r2_score(y_test, y_pred),
        rf_r2,
        r2_score(y_test, gb_y_pred)
    ]
})

print(results)


